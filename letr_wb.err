wandb: Currently logged in as: alexis-tabin (hogliners). Use `wandb login --relogin` to force relogin
/cluster/scratch/atabin/miniconda3/envs/deepl/lib/python3.10/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
/cluster/scratch/atabin/miniconda3/envs/deepl/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.
  warnings.warn(msg)
/cluster/scratch/atabin/miniconda3/envs/deepl/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.
  warnings.warn(msg)
/cluster/scratch/atabin/miniconda3/envs/deepl/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.
  warnings.warn(msg)
/cluster/scratch/atabin/miniconda3/envs/deepl/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.
  warnings.warn(msg)
/cluster/scratch/atabin/miniconda3/envs/deepl/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.
  warnings.warn(msg)
/cluster/scratch/atabin/miniconda3/envs/deepl/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.
  warnings.warn(msg)
/cluster/scratch/atabin/miniconda3/envs/deepl/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/cluster/scratch/atabin/miniconda3/envs/deepl/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.
  warnings.warn(msg)
wandb: Currently logged in as: alexis-tabin (hogliners). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.7
wandb: Run data is saved locally in /cluster/scratch/atabin/LETR_euler/wandb/run-20230110_172852-3eaxxtbs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scarlet-rain-12
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hogliners/letr
wandb: üöÄ View run at https://wandb.ai/hogliners/letr/runs/3eaxxtbs
Traceback (most recent call last):
  File "/cluster/scratch/atabin/LETR_euler/src/main.py", line 230, in <module>
Traceback (most recent call last):
  File "/cluster/scratch/atabin/LETR_euler/src/main.py", line 230, in <module>
    main(args)
  File "/cluster/scratch/atabin/LETR_euler/src/main.py", line 191, in main
    train_stats = train_one_epoch(model, criterion, postprocessors, data_loader_train, optimizer, device, epoch, args.clip_max_norm, args)
  File "/cluster/scratch/atabin/LETR_euler/src/engine.py", line 61, in train_one_epoch
    main(args)
  File "/cluster/scratch/atabin/LETR_euler/src/main.py", line 191, in main
    train_stats = train_one_epoch(model, criterion, postprocessors, data_loader_train, optimizer, device, epoch, args.clip_max_norm, args)
  File "/cluster/scratch/atabin/LETR_euler/src/engine.py", line 61, in train_one_epoch
    wandb.watch(model)
  File "/cluster/scratch/atabin/miniconda3/envs/deepl/lib/python3.10/site-packages/wandb/sdk/wandb_watch.py", line 54, in watch
    wandb.watch(model)
  File "/cluster/scratch/atabin/miniconda3/envs/deepl/lib/python3.10/site-packages/wandb/sdk/wandb_watch.py", line 54, in watch
Traceback (most recent call last):
  File "/cluster/scratch/atabin/LETR_euler/src/main.py", line 230, in <module>
Traceback (most recent call last):
  File "/cluster/scratch/atabin/LETR_euler/src/main.py", line 230, in <module>
Traceback (most recent call last):
  File "/cluster/scratch/atabin/LETR_euler/src/main.py", line 230, in <module>
    main(args)
  File "/cluster/scratch/atabin/LETR_euler/src/main.py", line 191, in main
Traceback (most recent call last):
  File "/cluster/scratch/atabin/LETR_euler/src/main.py", line 230, in <module>
    main(args)
  File "/cluster/scratch/atabin/LETR_euler/src/main.py", line 191, in main
    main(args)
  File "/cluster/scratch/atabin/LETR_euler/src/main.py", line 191, in main
    train_stats = train_one_epoch(model, criterion, postprocessors, data_loader_train, optimizer, device, epoch, args.clip_max_norm, args)
  File "/cluster/scratch/atabin/LETR_euler/src/engine.py", line 61, in train_one_epoch
    train_stats = train_one_epoch(model, criterion, postprocessors, data_loader_train, optimizer, device, epoch, args.clip_max_norm, args)
  File "/cluster/scratch/atabin/LETR_euler/src/engine.py", line 61, in train_one_epoch
Traceback (most recent call last):
  File "/cluster/scratch/atabin/LETR_euler/src/main.py", line 230, in <module>
    main(args)
  File "/cluster/scratch/atabin/LETR_euler/src/main.py", line 191, in main
    wandb.watch(model)
  File "/cluster/scratch/atabin/miniconda3/envs/deepl/lib/python3.10/site-packages/wandb/sdk/wandb_watch.py", line 54, in watch
    train_stats = train_one_epoch(model, criterion, postprocessors, data_loader_train, optimizer, device, epoch, args.clip_max_norm, args)
  File "/cluster/scratch/atabin/LETR_euler/src/engine.py", line 61, in train_one_epoch
    main(args)
  File "/cluster/scratch/atabin/LETR_euler/src/main.py", line 191, in main
    wandb.watch(model)
  File "/cluster/scratch/atabin/miniconda3/envs/deepl/lib/python3.10/site-packages/wandb/sdk/wandb_watch.py", line 54, in watch
    train_stats = train_one_epoch(model, criterion, postprocessors, data_loader_train, optimizer, device, epoch, args.clip_max_norm, args)
  File "/cluster/scratch/atabin/LETR_euler/src/engine.py", line 61, in train_one_epoch
    wandb.watch(model)
  File "/cluster/scratch/atabin/miniconda3/envs/deepl/lib/python3.10/site-packages/wandb/sdk/wandb_watch.py", line 54, in watch
    raise ValueError("You must call `wandb.init` before calling watch")
ValueError: You must call `wandb.init` before calling watch
        raise ValueError("You must call `wandb.init` before calling watch")raise ValueError("You must call `wandb.init` before calling watch")

ValueErrorValueError: : You must call `wandb.init` before calling watchYou must call `wandb.init` before calling watch

    raise ValueError("You must call `wandb.init` before calling watch")
ValueError: You must call `wandb.init` before calling watch
    wandb.watch(model)
  File "/cluster/scratch/atabin/miniconda3/envs/deepl/lib/python3.10/site-packages/wandb/sdk/wandb_watch.py", line 54, in watch
    raise ValueError("You must call `wandb.init` before calling watch")
ValueError: You must call `wandb.init` before calling watch
    train_stats = train_one_epoch(model, criterion, postprocessors, data_loader_train, optimizer, device, epoch, args.clip_max_norm, args)
  File "/cluster/scratch/atabin/LETR_euler/src/engine.py", line 61, in train_one_epoch
    raise ValueError("You must call `wandb.init` before calling watch")
ValueError: You must call `wandb.init` before calling watch
    wandb.watch(model)
  File "/cluster/scratch/atabin/miniconda3/envs/deepl/lib/python3.10/site-packages/wandb/sdk/wandb_watch.py", line 54, in watch
    raise ValueError("You must call `wandb.init` before calling watch")
ValueError: You must call `wandb.init` before calling watch
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 9464 closing signal SIGTERM
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 1 (pid: 9465) of binary: /cluster/scratch/atabin/miniconda3/envs/deepl/bin/python3
Traceback (most recent call last):
  File "/cluster/scratch/atabin/miniconda3/envs/deepl/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/cluster/scratch/atabin/miniconda3/envs/deepl/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/cluster/scratch/atabin/miniconda3/envs/deepl/lib/python3.10/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/cluster/scratch/atabin/miniconda3/envs/deepl/lib/python3.10/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/cluster/scratch/atabin/miniconda3/envs/deepl/lib/python3.10/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/cluster/scratch/atabin/miniconda3/envs/deepl/lib/python3.10/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/cluster/scratch/atabin/miniconda3/envs/deepl/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/cluster/scratch/atabin/miniconda3/envs/deepl/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
src/main.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2023-01-10_17:29:54
  host      : eu-lo-s4-033.euler.ethz.ch
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 9466)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2023-01-10_17:29:54
  host      : eu-lo-s4-033.euler.ethz.ch
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 9467)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2023-01-10_17:29:54
  host      : eu-lo-s4-033.euler.ethz.ch
  rank      : 4 (local_rank: 4)
  exitcode  : 1 (pid: 9468)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[4]:
  time      : 2023-01-10_17:29:54
  host      : eu-lo-s4-033.euler.ethz.ch
  rank      : 5 (local_rank: 5)
  exitcode  : 1 (pid: 9469)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[5]:
  time      : 2023-01-10_17:29:54
  host      : eu-lo-s4-033.euler.ethz.ch
  rank      : 6 (local_rank: 6)
  exitcode  : 1 (pid: 9470)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[6]:
  time      : 2023-01-10_17:29:54
  host      : eu-lo-s4-033.euler.ethz.ch
  rank      : 7 (local_rank: 7)
  exitcode  : 1 (pid: 9471)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-01-10_17:29:54
  host      : eu-lo-s4-033.euler.ethz.ch
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 9465)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
wandb: ERROR Failed to sample metric: process no longer exists (pid=9464)
Exception in thread MsgRouterThr:
Traceback (most recent call last):
  File "/cluster/scratch/atabin/miniconda3/envs/deepl/lib/python3.10/threading.py", line 1016, in _bootstrap_inner
